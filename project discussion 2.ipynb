{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data From the Local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Concrete_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(x=\"Age\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that in the starting the strength is weak but it solidifies with the time and again it loses its strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"FA\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 750 to 900 fine aggregate,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"CA\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 950 to 1100 fine aggregate,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Superplasticizer\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 5 to 12 fine Superplasticizer,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Water\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 160 to 200 fine Superplasticizer,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Fly Ash\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 100 to 175 of Fly Ash,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Blast\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 0 to 200 of Blast,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"Cement\",y=\"CMS\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome shows with the density of 100 to 400 of Blast,maximum compressive strength lies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.heatmap(df.corr(),annot=True,linewidths=0.5,linecolor=\"black\",fmt='.2f')  #fmt .2f for two decimal points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positively correlated columns has a great impact on the target column while the negative correlated has less or zero impact on the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(round(df.describe()[1:].transpose(),2),linewidth=2,annot=True,fmt=\"f\")\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Variables summary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now use subplot and displot to check data are normalized or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "cols=['Cement', 'Blast', 'Fly Ash', 'Water', 'Superplasticizer', 'CA', 'FA',\n",
    "       'Age', 'CMS']\n",
    "length=len(cols)\n",
    "cs=[\"b\",\"r\",\"g\",\"c\",\"m\",\"k\",\"lime\"]\n",
    "fig=plt.figure(figsize=(13,25))\n",
    "\n",
    "for i,j,k in itertools.zip_longest(cols,range(length),cs):\n",
    "    plt.subplot(4,2,j+1)\n",
    "    ax=sns.distplot(df[i],color=k,rug=True)\n",
    "    ax.set_facecolor(\"w\")\n",
    "    plt.axvline(df[i].mean(),linestyle=\"dashed\",label=\"mean\",color=\"k\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(i,color=\"navy\")\n",
    "    plt.xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above observation it is clear that the data are not normalized and we should proceed with the data cleaning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(edgecolor=\"red\",linewidth=1.5,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "df.corr()['CMS'].sort_values(ascending=False).drop(['CMS'])\n",
    "plt.xlabel('Feature',fontsize=14)\n",
    "plt.ylabel(\"Correlation with target column\",fontsize=14)\n",
    "plt.title(\"Correlation of features with the target column\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bara goes upper of 0 is positively correlated. Goes down 0 is nagetavely correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above observation the columns falls under high skewness :\n",
    "    \n",
    "    Age,Superplasticizer,Blast\n",
    "    \n",
    "But the columns have good correlation with the target column. Dropping of such column should not be good approach    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation:\n",
    "\n",
    "we need to transform those columns which has skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cement\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Blast\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fly Ash\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Water\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Superplasticizer\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CA\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FA\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CMS\"].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the percentage of data falls under outliers:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(df))\n",
    "threshold=3\n",
    "np.where(z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=df[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage loss of data while removing outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_loss=((49)/1030)*100   #1030-981=49\n",
    "print(percentage_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of outliers are less than 5 percent.We can proceed with the outliers removable\n",
    "\n",
    "Sometimes z-score unable to remove outliers.So we prefer IQR here over z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=df.quantile(0.25)\n",
    "q3=df.quantile(0.75)\n",
    "IQR=q3-q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1=df[~((df<(q1-1.5*IQR))|(df>(q3+1.5*IQR))).any(axis=1)]\n",
    "print(df_new1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_loss=((1030-941)/1030)*100\n",
    "print(percentage_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage loss in the z-score is less so we prefer z-score over IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_new.iloc[:,:-1]\n",
    "y=df_new.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing skewnes by transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform     #box-cox is only for positive but yeo-johnson is for both negative and positive\n",
    "x=power_transform(x,method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Building:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_t=sc.fit_transform(x)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scr=0\n",
    "for i in range(0,1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x_t,y,test_size=.20,random_state=i)\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred_train=lr.predict(x_train)\n",
    "    pred_test=lr.predict(x_test)\n",
    "    if round(r2_score(y_train,pred_train)*100,2)==round(r2_score(y_test,pred_test)*100,2):\n",
    "        print(\"At random state\",i,\"The model performs very well\")\n",
    "        print(\"At random state :-\",i)\n",
    "        print(\"Training r2_score is :-\",r2_score(y_train,pred_train)*100)\n",
    "        print(\"Testing r2_score is :-\",r2_score(y_test,pred_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_t,y,test_size=.20,random_state=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use random state 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters={'alpha':[.0001,.001,.01,.1,1,10],'random_state':list(range(0,10))}\n",
    "ls=Lasso()\n",
    "clf=GridSearchCV(ls,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=Lasso(alpha=.0001,random_state=0)\n",
    "ls.fit(x_train,y_train)\n",
    "ls.score(x_train,y_train)\n",
    "pred_ls=ls.predict(x_test)\n",
    "\n",
    "lss=r2_score(y_test,pred_ls)\n",
    "for j in range (2,10):\n",
    "    lsscore=cross_val_score(ls,x_t,y,cv=j)\n",
    "    lsc=lsscore.mean()\n",
    "    print(\"At cv:-\",j)\n",
    "    print(\"Cross Validation Score is :- \", lsc*100)\n",
    "    print(\"R2 score is :-\", lss*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"At cv:-\",3)\n",
    "print(\"Cross Validation Score is :- \", 71.650)\n",
    "print(\"R2 score is :-\", 81.210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of cv should be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_ls))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_ls))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_ls,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('Lasso Regression',fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results shows that the datapoints near the best fit line. Trying model testing with different algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "parameters={'alpha':[.0001,.001,.01,.1,1,10],'copy_X':[True,False],'random_state':list(range(0,10)),'fit_intercept':[True,False],'normalize':[True,False],'tol':[.0001,.001,.01,.1,1,10]}\n",
    "rd=Ridge()\n",
    "clf=GridSearchCV(rd,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd=Ridge(alpha=0.01, copy_X= True, fit_intercept= True, normalize= True, random_state= 0, tol= 0.0001)\n",
    "rd.fit(x_train,y_train)\n",
    "rd.score(x_train,y_train)\n",
    "pred_rd=rd.predict(x_test)\n",
    "\n",
    "rds=r2_score(y_test,pred_rd)\n",
    "print('R2 Score:',rds*100)\n",
    "\n",
    "rdscore=cross_val_score(rd,x_t,y,cv=3)\n",
    "rdc=rdscore.mean()\n",
    "print('Cross Val Score : ',rdc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_rd))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_rd))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_rd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_rd,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('Ridge Regression',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Techniques : \n",
    "\n",
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "parameters={'criterion':['mse','friedman_mse','mae'],'splitter':['best','random']}\n",
    "dt=DecisionTreeRegressor()\n",
    "clf=GridSearchCV(dt,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeRegressor(criterion= 'mse', splitter= 'best')\n",
    "dt.fit(x_train,y_train)\n",
    "dt.score(x_train,y_train)\n",
    "pred_dt=dt.predict(x_test)\n",
    "\n",
    "dts=r2_score(y_test,pred_dt)\n",
    "print('R2 Score:',dts*100)\n",
    "\n",
    "dtscore=cross_val_score(dt,x_t,y,cv=3)\n",
    "dtc=dtscore.mean()\n",
    "print('Cross Val Score : ',dtc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_dt))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_dt))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_dt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_dt,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('Decision Tree Regression',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters={'criterion':['mse','friedman_mse','mae'],'n_estimators':[100,200,300]}  #Search in google for more parameter\n",
    "rf=RandomForestRegressor()\n",
    "clf=GridSearchCV(rf,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(criterion= 'mae', n_estimators= 200)\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_train,y_train)\n",
    "pred_rf=rf.predict(x_test)\n",
    "\n",
    "rfs=r2_score(y_test,pred_rf)\n",
    "print('R2 Score:',rfs*100)\n",
    "\n",
    "rfscore=cross_val_score(rf,x_t,y,cv=3)\n",
    "rfc=rfscore.mean()\n",
    "print('Cross Val Score : ',rfc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_rf))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_rf))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_rf,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('Random Forest Regression',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "parameters={'loss':['ls', 'lad', 'huber', 'quantile'],'n_estimators':[50,100,200],'criterion':['friedman_mse', 'mse', 'mae']}  #Search in google for more parameter\n",
    "gbr=GradientBoostingRegressor()\n",
    "clf=GridSearchCV(gbr,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr=GradientBoostingRegressor()\n",
    "gbr.fit(x_train,y_train)\n",
    "gbr.score(x_train,y_train)\n",
    "pred_gbr=gbr.predict(x_test)\n",
    "\n",
    "gbrs=r2_score(y_test,pred_gbr)\n",
    "print('R2 Score:',gbrs*100)\n",
    "\n",
    "gbrscore=cross_val_score(gbr,x_t,y,cv=3)\n",
    "gbrc=gbrscore.mean()\n",
    "print('Cross Val Score : ',gbrc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_gbr))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_gbr))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_gbr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_gbr,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('Gradient Boosting Regressor',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "parameters={'kernel':['linear', 'poly', 'rbf', 'sigmoid'],'gamma':['scale','auto']}  #'gamma':['scale','auto']\n",
    "sv=SVR()\n",
    "clf=GridSearchCV(sv,parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv=SVR(kernel= 'linear',gamma='scale')\n",
    "sv.fit(x_train,y_train)\n",
    "sv.score(x_train,y_train)\n",
    "pred_sv=sv.predict(x_test)\n",
    "\n",
    "svs=r2_score(y_test,pred_sv)\n",
    "print('R2 Score:',svs*100)\n",
    "\n",
    "svscore=cross_val_score(sv,x_t,y,cv=3)\n",
    "svc=svscore.mean()\n",
    "print('Cross Val Score : ',svc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error\")\n",
    "print(\"Mean Absolute Eror : \",mean_absolute_error(y_test,pred_sv))\n",
    "print(\"Mean Squared Eror : \",mean_squared_error(y_test,pred_sv))\n",
    "print(\"Root Mean Squared Eror : \",np.sqrt(mean_squared_error(y_test,pred_sv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x=y_test,y=pred_sv,color='r')\n",
    "plt.plot(y_test,y_test,color='b')\n",
    "plt.xlabel(\"Actual compressive strength\",fontsize=14)\n",
    "plt.ylabel(\"Predicted compressive strength\",fontsize=14)\n",
    "plt.title('SVR',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best model is Lasso.Since the difference between the percentage score of cross validation and r2_score is optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='inhouse_concrete.pkl'\n",
    "pickle.dump(ls,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inhouse_concrete.pkl','rb') as f:\n",
    "    x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array(y_test)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=np.array(ls.predict(x_test))\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_com=pd.DataFrame({\"original\":a,\"predicted\":predicted},index=range(len(a)))\n",
    "df_com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above table the model is predicted the values with 70-80 percent accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get all the datasets in UCI repository"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
